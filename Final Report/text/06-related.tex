\section{Related Work}
\label{sec:related}

Detecting exotic particles in high-energy physics (HEP) using data analytics techniques instead of the traditionally used physical detectors~\cite{detectors} is not new. Cutts et al. are among the first to use neural networks to identify interesting events in HEP experiments~\cite{Cutts-NN1}. This was quickly followed by several attempts  improve the classification accuracy of neural networks~\cite{NN2,NN3}. Apart from the widely popular techniques based on neural networks, only decision trees were explored for a long time. Bowser-Chao and Dzialo used binary decision trees to detect top quarks and compared their results with neural networks~\cite{Binary-DT}. The conventional wisdom was that neural networks were by far the best when it comes to classification in HEP until Roe et al. came along and projected boosted decision trees as an alternative to artificial neural networks~\cite{Boosted-DT}. By combining several \emph{weak} classifiers, Roe et al. showed that it is possible to obtain better accuracy than a neural network. However, more recently, Baldi et al. showed that a deep learning neural network with several hidden layers outperforms the boosted decision tree~\cite{DeepNN}. While a number of classification techniques have been developed and applied over the last several years, the HEP community has so far explored only neural networks and boosted decision trees in any depth. This lead to the development of statistical packages for the HEP community such as StatPatternRecognition so that several other techniques based on Rotation Forest, Discriminant Analysis etc. could be explored~\cite{StatPatternRecognition}. Despite this effort, no documented work exists in HEP where alternative techniques are explored even though other techniques are thought to be inferior.

Since Baldi et al.~\cite{DeepNN} work is closest to ours, we describe it in detail here. The authors of this paper used deep learning methods of neural network to find exotic particles in high energy particle colliders. Deep learning models are neural networks with multiple hidden networks. Current technics like shallow models which are single hidden layer feedforward network fail to capture all features.
The deep learning model here is used on 2.6 million training examples and 100,000 validation examples. The mode is a five-layer neural network with 300 hidden units in each layer, learning rate of 0.05, and a weight decay coefficient of 0.00001 . Testing is done on 500,000 examples. For Higgs benchmark, Area Under the Curve(AUC) - complete for deep neural network is 0.88 and for shallow neural network, it is 0.81.
